#!/usr/bin/env python3
"""
Memory System v1.2.4 - SQLite Backend
ç‹¬ç«‹çš„ SQLite åç«¯æ¨¡å—ï¼Œä¸å½±å“ç°æœ‰ JSONL ç³»ç»Ÿ
"""

import json
import sqlite3
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

# ============================================================
# æ•°æ®åº“ Schema
# ============================================================

SCHEMA_SQL = """
-- ä¸»è¡¨ï¼šè®°å¿†
CREATE TABLE IF NOT EXISTS memories (
    id TEXT PRIMARY KEY,
    type TEXT NOT NULL CHECK(type IN ('fact', 'belief', 'summary')),
    content TEXT NOT NULL,

    -- è¯„åˆ†ç³»ç»Ÿ
    importance REAL DEFAULT 0.5,
    score REAL DEFAULT 1.0,
    access_boost REAL DEFAULT 0.0,
    final_score REAL GENERATED ALWAYS AS (score + access_boost) STORED,

    -- æ—¶é—´å­—æ®µ
    created TEXT NOT NULL,
    updated TEXT,
    last_accessed TEXT,

    -- è®¿é—®ç»Ÿè®¡
    access_count INTEGER DEFAULT 0,
    retrieval_count INTEGER DEFAULT 0,

    -- æ¥æºå’ŒçŠ¶æ€
    source TEXT,
    state INTEGER DEFAULT 0 CHECK(state IN (0, 1, 2)),

    -- å†²çªç®¡ç†
    conflict_downgraded INTEGER DEFAULT 0,
    downgrade_reason TEXT,
    superseded INTEGER DEFAULT 0,
    superseded_by TEXT,

    -- TTL ç®¡ç†
    ttl_days INTEGER,
    auto_delete_at TEXT,

    -- ç±»å‹ç‰¹æœ‰å­—æ®µ
    confidence REAL,
    basis TEXT,
    extract_method TEXT,
    expires_at TEXT,
    is_permanent INTEGER DEFAULT 1
);

-- å®ä½“å…³è”è¡¨
CREATE TABLE IF NOT EXISTS memory_entities (
    memory_id TEXT NOT NULL,
    entity TEXT NOT NULL,
    PRIMARY KEY (memory_id, entity),
    FOREIGN KEY (memory_id) REFERENCES memories(id) ON DELETE CASCADE
);

-- å…³ç³»ä¸‰å…ƒç»„è¡¨
CREATE TABLE IF NOT EXISTS memory_relations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    memory_id TEXT NOT NULL,
    subject TEXT NOT NULL,
    relation_type TEXT NOT NULL,
    object TEXT NOT NULL,
    confidence REAL DEFAULT 1.0,
    created TEXT NOT NULL,
    superseded INTEGER DEFAULT 0,
    FOREIGN KEY (memory_id) REFERENCES memories(id) ON DELETE CASCADE
);

-- æ‘˜è¦æ¥æºè¡¨
CREATE TABLE IF NOT EXISTS summary_sources (
    summary_id TEXT NOT NULL,
    source_fact_id TEXT NOT NULL,
    PRIMARY KEY (summary_id, source_fact_id),
    FOREIGN KEY (summary_id) REFERENCES memories(id) ON DELETE CASCADE
);

-- è®¿é—®æ—¥å¿—è¡¨ï¼ˆå¯é€‰ï¼‰
CREATE TABLE IF NOT EXISTS access_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    memory_id TEXT NOT NULL,
    access_type TEXT NOT NULL,
    timestamp TEXT NOT NULL,
    FOREIGN KEY (memory_id) REFERENCES memories(id) ON DELETE CASCADE
);

-- v1.6.0: å‘é‡å­˜å‚¨è¡¨
CREATE TABLE IF NOT EXISTS memory_vectors (
    id TEXT PRIMARY KEY,
    memory_id TEXT NOT NULL,
    vector BLOB NOT NULL,
    dimension INTEGER NOT NULL,
    provider TEXT DEFAULT 'openai',
    model TEXT DEFAULT 'text-embedding-3-small',
    created TEXT NOT NULL,
    FOREIGN KEY (memory_id) REFERENCES memories(id) ON DELETE CASCADE
);

-- v1.6.0: åµŒå…¥ç¼“å­˜è¡¨
CREATE TABLE IF NOT EXISTS embedding_cache (
    text_hash TEXT PRIMARY KEY,
    embedding BLOB NOT NULL,
    dimension INTEGER NOT NULL,
    provider TEXT,
    model TEXT,
    created TEXT NOT NULL
);

-- ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_memories_state_score ON memories(state, final_score DESC);
CREATE INDEX IF NOT EXISTS idx_memories_type ON memories(type);
CREATE INDEX IF NOT EXISTS idx_memories_created ON memories(created DESC);
CREATE INDEX IF NOT EXISTS idx_memories_auto_delete ON memories(auto_delete_at) WHERE auto_delete_at IS NOT NULL;
CREATE INDEX IF NOT EXISTS idx_entities_entity ON memory_entities(entity);
CREATE INDEX IF NOT EXISTS idx_relations_subject_type ON memory_relations(subject, relation_type, superseded);
CREATE INDEX IF NOT EXISTS idx_access_log_timestamp ON access_log(timestamp DESC);
CREATE INDEX IF NOT EXISTS idx_vectors_memory_id ON memory_vectors(memory_id);
"""

# ============================================================
# æ•°æ®åº“è¿æ¥ç®¡ç†
# ============================================================


class SQLiteBackend:
    """SQLite åç«¯ç®¡ç†å™¨"""

    def __init__(self, memory_dir: Path):
        self.memory_dir = Path(memory_dir)
        self.db_path = self.memory_dir / "layer2" / "memories.db"
        self._ensure_db_exists()

    def _ensure_db_exists(self):
        """ç¡®ä¿æ•°æ®åº“å­˜åœ¨å¹¶åˆå§‹åŒ–"""
        if not self.db_path.exists():
            self.db_path.parent.mkdir(parents=True, exist_ok=True)
            self._init_db()

    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = self._get_connection()
        try:
            # å¯ç”¨ WAL æ¨¡å¼ï¼ˆæå‡å¹¶å‘æ€§èƒ½ï¼‰
            conn.execute("PRAGMA journal_mode=WAL")
            conn.execute("PRAGMA synchronous=NORMAL")

            # åˆ›å»ºè¡¨å’Œç´¢å¼•
            conn.executescript(SCHEMA_SQL)
            conn.commit()
            print(f"âœ… SQLite æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {self.db_path}")
        finally:
            conn.close()

    def _get_connection(self) -> sqlite3.Connection:
        """è·å–æ•°æ®åº“è¿æ¥"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row  # è¿”å›å­—å…¸
        return conn

    # ============================================================
    # åŸºç¡€ CRUD æ“ä½œ
    # ============================================================

    def insert_memory(self, record: Dict[str, Any]) -> bool:
        """æ’å…¥è®°å¿†"""
        conn = self._get_connection()
        try:
            cursor = conn.cursor()

            # æ’å…¥ä¸»è¡¨
            cursor.execute(
                """
                INSERT OR REPLACE INTO memories (
                    id, type, content, importance, score, access_boost,
                    created, updated, last_accessed,
                    access_count, retrieval_count,
                    source, state,
                    conflict_downgraded, downgrade_reason, superseded, superseded_by,
                    ttl_days, auto_delete_at,
                    confidence, basis, extract_method, expires_at, is_permanent
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    record["id"],
                    record.get("type", "fact"),
                    record["content"],
                    record.get("importance", 0.5),
                    record.get("score", 1.0),
                    record.get("access_boost", 0.0),
                    record.get("created", record.get("created_at")),
                    record.get("updated"),
                    record.get("last_accessed"),
                    record.get("access_count", 0),
                    record.get("retrieval_count", 0),
                    record.get("source", "unknown"),
                    0,  # state: Active
                    1 if record.get("conflict_downgraded") else 0,
                    record.get("downgrade_reason"),
                    1 if record.get("superseded") else 0,
                    record.get("superseded_by"),
                    record.get("ttl_days"),
                    record.get("auto_delete_at"),
                    record.get("confidence"),
                    record.get("basis"),
                    record.get("extract_method"),
                    record.get("expires_at"),
                    1 if record.get("is_permanent", True) else 0,
                ),
            )

            # æ’å…¥å®ä½“
            for entity in record.get("entities", []):
                cursor.execute(
                    """
                    INSERT OR IGNORE INTO memory_entities (memory_id, entity)
                    VALUES (?, ?)
                """,
                    (record["id"], entity),
                )

            # æ’å…¥æ‘˜è¦æ¥æºï¼ˆå¦‚æœæ˜¯ summaryï¼‰
            if record.get("type") == "summary" and "source_facts" in record:
                for source_id in record["source_facts"]:
                    cursor.execute(
                        """
                        INSERT OR IGNORE INTO summary_sources (summary_id, source_fact_id)
                        VALUES (?, ?)
                    """,
                        (record["id"], source_id),
                    )

            conn.commit()
            return True
        except Exception as e:
            print(f"âŒ æ’å…¥è®°å¿†å¤±è´¥: {e}")
            conn.rollback()
            return False
        finally:
            conn.close()

    def get_memory(self, memory_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å•æ¡è®°å¿†"""
        conn = self._get_connection()
        try:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM memories WHERE id = ?", (memory_id,))
            row = cursor.fetchone()

            if not row:
                return None

            # è½¬æ¢ä¸ºå­—å…¸
            memory = dict(row)

            # åŠ è½½å®ä½“
            cursor.execute("SELECT entity FROM memory_entities WHERE memory_id = ?", (memory_id,))
            memory["entities"] = [r["entity"] for r in cursor.fetchall()]

            # åŠ è½½æ‘˜è¦æ¥æºï¼ˆå¦‚æœæ˜¯ summaryï¼‰
            if memory["type"] == "summary":
                cursor.execute("SELECT source_fact_id FROM summary_sources WHERE summary_id = ?", (memory_id,))
                memory["source_facts"] = [r["source_fact_id"] for r in cursor.fetchall()]

            return memory
        finally:
            conn.close()

    def update_access_stats(self, memory_id: str, access_type: str) -> bool:
        """æ›´æ–°è®¿é—®ç»Ÿè®¡ï¼ˆO(1) æ“ä½œï¼‰"""
        conn = self._get_connection()
        try:
            cursor = conn.cursor()

            # æ›´æ–°ç»Ÿè®¡
            cursor.execute(
                """
                UPDATE memories
                SET access_count = access_count + 1,
                    retrieval_count = retrieval_count + CASE WHEN ? = 'retrieval' THEN 1 ELSE 0 END,
                    last_accessed = ?
                WHERE id = ?
            """,
                (access_type, datetime.utcnow().isoformat() + "Z", memory_id),
            )

            # è®°å½•è®¿é—®æ—¥å¿—ï¼ˆå¯é€‰ï¼‰
            cursor.execute(
                """
                INSERT INTO access_log (memory_id, access_type, timestamp)
                VALUES (?, ?, ?)
            """,
                (memory_id, access_type, datetime.utcnow().isoformat() + "Z"),
            )

            conn.commit()
            return True
        except Exception as e:
            print(f"âŒ æ›´æ–°è®¿é—®ç»Ÿè®¡å¤±è´¥: {e}")
            conn.rollback()
            return False
        finally:
            conn.close()

    def search_by_entities(self, entities: List[str], limit: int = 10) -> List[Dict[str, Any]]:
        """é€šè¿‡å®ä½“æœç´¢è®°å¿†"""
        conn = self._get_connection()
        try:
            cursor = conn.cursor()

            placeholders = ",".join("?" * len(entities))
            cursor.execute(
                f"""
                SELECT m.*, GROUP_CONCAT(me.entity) as matched_entities
                FROM memories m
                JOIN memory_entities me ON m.id = me.memory_id
                WHERE me.entity IN ({placeholders})
                  AND m.state = 0
                GROUP BY m.id
                ORDER BY m.final_score DESC
                LIMIT ?
            """,
                (*entities, limit),
            )

            results = []
            for row in cursor.fetchall():
                memory = dict(row)
                # åŠ è½½å®Œæ•´å®ä½“åˆ—è¡¨
                cursor.execute("SELECT entity FROM memory_entities WHERE memory_id = ?", (memory["id"],))
                memory["entities"] = [r["entity"] for r in cursor.fetchall()]
                results.append(memory)

            return results
        finally:
            conn.close()

    def get_all_active_memories(self, mem_type: Optional[str] = None) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰æ´»è·ƒè®°å¿†"""
        conn = self._get_connection()
        try:
            cursor = conn.cursor()

            if mem_type:
                cursor.execute(
                    """
                    SELECT * FROM memories
                    WHERE state = 0 AND type = ?
                    ORDER BY final_score DESC
                """,
                    (mem_type,),
                )
            else:
                cursor.execute("""
                    SELECT * FROM memories
                    WHERE state = 0
                    ORDER BY final_score DESC
                """)

            results = []
            for row in cursor.fetchall():
                memory = dict(row)
                # åŠ è½½å®ä½“
                cursor.execute("SELECT entity FROM memory_entities WHERE memory_id = ?", (memory["id"],))
                memory["entities"] = [r["entity"] for r in cursor.fetchall()]
                results.append(memory)

            return results
        finally:
            conn.close()

    def archive_memory(self, memory_id: str) -> bool:
        """å½’æ¡£è®°å¿†"""
        conn = self._get_connection()
        try:
            cursor = conn.cursor()
            cursor.execute("UPDATE memories SET state = 1 WHERE id = ?", (memory_id,))
            conn.commit()
            return True
        except Exception as e:
            print(f"âŒ å½’æ¡£è®°å¿†å¤±è´¥: {e}")
            conn.rollback()
            return False
        finally:
            conn.close()

    def ttl_cleanup(self) -> int:
        """TTL æ¸…ç†ï¼šæ ‡è®°è¿‡æœŸè®°å¿†ä¸º Junk"""
        conn = self._get_connection()
        try:
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE memories
                SET state = 2
                WHERE auto_delete_at IS NOT NULL
                  AND auto_delete_at < datetime('now')
                  AND state = 0
            """)
            deleted = cursor.rowcount
            conn.commit()
            return deleted
        finally:
            conn.close()

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        conn = self._get_connection()
        try:
            cursor = conn.cursor()

            # æ€»è®°å¿†æ•°
            cursor.execute("SELECT COUNT(*) as total FROM memories WHERE state = 0")
            total = cursor.fetchone()["total"]

            # æŒ‰ç±»å‹ç»Ÿè®¡
            cursor.execute("""
                SELECT type, COUNT(*) as count
                FROM memories
                WHERE state = 0
                GROUP BY type
            """)
            by_type = {row["type"]: row["count"] for row in cursor.fetchall()}

            # å½’æ¡£æ•°
            cursor.execute("SELECT COUNT(*) as archived FROM memories WHERE state = 1")
            archived = cursor.fetchone()["archived"]

            return {
                "total": total,
                "facts": by_type.get("fact", 0),
                "beliefs": by_type.get("belief", 0),
                "summaries": by_type.get("summary", 0),
                "archived": archived,
            }
        finally:
            conn.close()

    # ============================================================
    # v1.6.0: å‘é‡ç›¸å…³æ“ä½œ
    # ============================================================

    def insert_vector(
        self,
        memory_id: str,
        vector: List[float],
        provider: str = "openai",
        model: str = "text-embedding-3-small",
    ) -> bool:
        """æ’å…¥è®°å¿†å‘é‡"""
        import numpy as np

        conn = self._get_connection()
        try:
            cursor = conn.cursor()
            vector_blob = np.array(vector, dtype=np.float32).tobytes()
            dimension = len(vector)

            cursor.execute(
                """
                INSERT OR REPLACE INTO memory_vectors
                (id, memory_id, vector, dimension, provider, model, created)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    memory_id,
                    memory_id,
                    vector_blob,
                    dimension,
                    provider,
                    model,
                    datetime.utcnow().isoformat() + "Z",
                ),
            )

            conn.commit()
            return True
        except Exception as e:
            print(f"âŒ æ’å…¥å‘é‡å¤±è´¥: {e}")
            conn.rollback()
            return False
        finally:
            conn.close()

    def get_vector(self, memory_id: str) -> Optional[List[float]]:
        """è·å–è®°å¿†å‘é‡"""
        import numpy as np

        conn = self._get_connection()
        try:
            cursor = conn.cursor()
            cursor.execute(
                "SELECT vector FROM memory_vectors WHERE memory_id = ?",
                (memory_id,),
            )
            row = cursor.fetchone()
            if row:
                return np.frombuffer(row["vector"], dtype=np.float32).tolist()
            return None
        finally:
            conn.close()

    def search_vectors(
        self,
        query_vector: List[float],
        top_k: int = 10,
        memory_type: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        """å‘é‡ç›¸ä¼¼åº¦æœç´¢"""
        import numpy as np

        conn = self._get_connection()
        try:
            cursor = conn.cursor()

            if memory_type:
                cursor.execute(
                    """
                    SELECT mv.memory_id, mv.vector, m.content, m.type, m.importance
                    FROM memory_vectors mv
                    JOIN memories m ON mv.memory_id = m.id
                    WHERE m.state = 0 AND m.type = ?
                """,
                    (memory_type,),
                )
            else:
                cursor.execute("""
                    SELECT mv.memory_id, mv.vector, m.content, m.type, m.importance
                    FROM memory_vectors mv
                    JOIN memories m ON mv.memory_id = m.id
                    WHERE m.state = 0
                """)

            query_vec = np.array(query_vector, dtype=np.float32)
            query_norm = np.linalg.norm(query_vec)

            if query_norm == 0:
                return []

            results = []
            for row in cursor.fetchall():
                vector = np.frombuffer(row["vector"], dtype=np.float32)
                vec_norm = np.linalg.norm(vector)

                if vec_norm == 0:
                    continue

                similarity = float(np.dot(query_vec, vector) / (query_norm * vec_norm))

                results.append(
                    {
                        "id": row["memory_id"],
                        "content": row["content"],
                        "type": row["type"],
                        "importance": row["importance"],
                        "similarity": similarity,
                    }
                )

            results.sort(key=lambda x: x["similarity"], reverse=True)
            return results[:top_k]
        finally:
            conn.close()

    def get_vector_count(self) -> int:
        """è·å–å‘é‡æ•°é‡"""
        conn = self._get_connection()
        try:
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) as count FROM memory_vectors")
            return cursor.fetchone()["count"]
        finally:
            conn.close()

    def cache_embedding(
        self,
        text_hash: str,
        embedding: List[float],
        provider: str = "openai",
        model: str = "text-embedding-3-small",
    ) -> bool:
        """ç¼“å­˜åµŒå…¥å‘é‡"""
        import numpy as np

        conn = self._get_connection()
        try:
            cursor = conn.cursor()
            embedding_blob = np.array(embedding, dtype=np.float32).tobytes()
            dimension = len(embedding)

            cursor.execute(
                """
                INSERT OR REPLACE INTO embedding_cache
                (text_hash, embedding, dimension, provider, model, created)
                VALUES (?, ?, ?, ?, ?, ?)
            """,
                (
                    text_hash,
                    embedding_blob,
                    dimension,
                    provider,
                    model,
                    datetime.utcnow().isoformat() + "Z",
                ),
            )

            conn.commit()
            return True
        except Exception:
            conn.rollback()
            return False
        finally:
            conn.close()

    def get_cached_embedding(self, text_hash: str) -> Optional[List[float]]:
        """è·å–ç¼“å­˜çš„åµŒå…¥å‘é‡"""
        import numpy as np

        conn = self._get_connection()
        try:
            cursor = conn.cursor()
            cursor.execute(
                "SELECT embedding FROM embedding_cache WHERE text_hash = ?",
                (text_hash,),
            )
            row = cursor.fetchone()
            if row:
                return np.frombuffer(row["embedding"], dtype=np.float32).tolist()
            return None
        finally:
            conn.close()


# ============================================================
# è¿ç§»å·¥å…·
# ============================================================


def migrate_jsonl_to_sqlite(memory_dir: Path, backup: bool = True) -> Tuple[int, int]:
    """
    è¿ç§» JSONL æ•°æ®åˆ° SQLite

    è¿”å›: (æˆåŠŸæ•°, å¤±è´¥æ•°)
    """
    backend = SQLiteBackend(memory_dir)

    success_count = 0
    fail_count = 0

    for mem_type in ["facts", "beliefs", "summaries"]:
        jsonl_path = memory_dir / "layer2" / "active" / f"{mem_type}.jsonl"

        if not jsonl_path.exists():
            continue

        # å¤‡ä»½
        if backup:
            backup_path = jsonl_path.with_suffix(".jsonl.backup")
            import shutil

            shutil.copy2(jsonl_path, backup_path)
            print(f"âœ… å¤‡ä»½: {jsonl_path} -> {backup_path}")

        # è¯»å–å¹¶è¿ç§»
        print(f"ğŸ“ è¿ç§» {mem_type}...")
        with open(jsonl_path, encoding="utf-8") as f:
            for line in f:
                if not line.strip():
                    continue

                try:
                    record = json.loads(line)
                    # ç¡®ä¿ type å­—æ®µæ­£ç¡®
                    if mem_type == "facts":
                        record["type"] = "fact"
                    elif mem_type == "beliefs":
                        record["type"] = "belief"
                    elif mem_type == "summaries":
                        record["type"] = "summary"

                    if backend.insert_memory(record):
                        success_count += 1
                    else:
                        fail_count += 1
                except Exception as e:
                    print(f"âŒ è¿ç§»å¤±è´¥ ({record.get('id', 'unknown')}): {e}")
                    fail_count += 1

    return success_count, fail_count


# ============================================================
# æµ‹è¯•å‡½æ•°
# ============================================================


def test_sqlite_backend(memory_dir: Path):
    """æµ‹è¯• SQLite åç«¯"""
    print("ğŸ§ª æµ‹è¯• SQLite åç«¯...")

    backend = SQLiteBackend(memory_dir)

    # æµ‹è¯•æ’å…¥
    test_record = {
        "id": "test_001",
        "type": "fact",
        "content": "è¿™æ˜¯ä¸€æ¡æµ‹è¯•è®°å¿†",
        "importance": 0.8,
        "score": 1.0,
        "created": datetime.utcnow().isoformat() + "Z",
        "entities": ["æµ‹è¯•", "SQLite"],
        "source": "test",
    }

    print("1. æµ‹è¯•æ’å…¥...")
    if backend.insert_memory(test_record):
        print("   âœ… æ’å…¥æˆåŠŸ")
    else:
        print("   âŒ æ’å…¥å¤±è´¥")
        return

    # æµ‹è¯•è¯»å–
    print("2. æµ‹è¯•è¯»å–...")
    memory = backend.get_memory("test_001")
    if memory and memory["content"] == "è¿™æ˜¯ä¸€æ¡æµ‹è¯•è®°å¿†":
        print("   âœ… è¯»å–æˆåŠŸ")
    else:
        print("   âŒ è¯»å–å¤±è´¥")
        return

    # æµ‹è¯•è®¿é—®ç»Ÿè®¡
    print("3. æµ‹è¯•è®¿é—®ç»Ÿè®¡...")
    if backend.update_access_stats("test_001", "retrieval"):
        memory = backend.get_memory("test_001")
        if memory["access_count"] == 1:
            print("   âœ… è®¿é—®ç»Ÿè®¡æˆåŠŸ")
        else:
            print("   âŒ è®¿é—®ç»Ÿè®¡å¤±è´¥")

    # æµ‹è¯•å®ä½“æœç´¢
    print("4. æµ‹è¯•å®ä½“æœç´¢...")
    results = backend.search_by_entities(["æµ‹è¯•"])
    if results and len(results) > 0:
        print(f"   âœ… æœç´¢æˆåŠŸï¼Œæ‰¾åˆ° {len(results)} æ¡è®°å¿†")
    else:
        print("   âŒ æœç´¢å¤±è´¥")

    # æµ‹è¯•ç»Ÿè®¡
    print("5. æµ‹è¯•ç»Ÿè®¡...")
    stats = backend.get_stats()
    print(f"   æ€»è®°å¿†æ•°: {stats['total']}")
    print(f"   Facts: {stats['facts']}")

    print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")


if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("ç”¨æ³•: python sqlite_backend.py <memory_dir> [test|migrate]")
        sys.exit(1)

    memory_dir = Path(sys.argv[1])
    action = sys.argv[2] if len(sys.argv) > 2 else "test"

    if action == "test":
        test_sqlite_backend(memory_dir)
    elif action == "migrate":
        print("ğŸ”„ å¼€å§‹è¿ç§» JSONL -> SQLite...")
        success, fail = migrate_jsonl_to_sqlite(memory_dir)
        print(f"\nâœ… è¿ç§»å®Œæˆ: æˆåŠŸ {success} æ¡, å¤±è´¥ {fail} æ¡")
