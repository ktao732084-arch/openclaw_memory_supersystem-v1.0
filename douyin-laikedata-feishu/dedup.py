#!/usr/bin/env python3
"""
é£ä¹¦æ•°æ®å»é‡å·¥å…·
"""
import requests
import json
from datetime import datetime

# é£ä¹¦é…ç½®
FEISHU_APP_ID = "cli_a90737e0f5b81cd3"
FEISHU_APP_SECRET = "REDACTED"
FEISHU_APP_TOKEN = "FEiCbGEDHarzyUsPG8QcoLxwn7d"
FEISHU_TABLE_ID = "tbl1n1PC1aooYdKk"

def get_feishu_token():
    """è·å–é£ä¹¦ tenant_access_token"""
    url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
    payload = {
        "app_id": FEISHU_APP_ID,
        "app_secret": FEISHU_APP_SECRET
    }
    headers = {"Content-Type": "application/json"}
    resp = requests.post(url, json=payload, headers=headers, timeout=10)
    
    if resp.status_code == 200:
        data = resp.json()
        if data.get('code') == 0:
            return data.get('tenant_access_token')
    return None

def get_existing_records(token, date_str=None):
    """è·å–é£ä¹¦ä¸­å·²å­˜åœ¨çš„è®°å½•"""
    print(f"ğŸ“‹ æŸ¥è¯¢é£ä¹¦ä¸­çš„ç°æœ‰è®°å½•...")
    
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{FEISHU_APP_TOKEN}/tables/{FEISHU_TABLE_ID}/records/search"
    
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }
    
    all_records = []
    page_token = None
    
    while True:
        payload = {
            "page_size": 500
        }
        
        # å¦‚æœæŒ‡å®šäº†æ—¥æœŸï¼Œæ·»åŠ è¿‡æ»¤æ¡ä»¶
        if date_str:
            payload["filter"] = {
                "conjunction": "and",
                "conditions": [
                    {
                        "field_name": "æ—¶é—´",
                        "operator": "is",
                        "value": [date_str]
                    }
                ]
            }
        
        if page_token:
            payload["page_token"] = page_token
        
        try:
            resp = requests.post(url, headers=headers, json=payload, timeout=30)
            result = resp.json()
            
            if result.get('code') == 0:
                data = result.get('data', {})
                items = data.get('items', [])
                all_records.extend(items)
                
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸‹ä¸€é¡µ
                if not data.get('has_more'):
                    break
                
                page_token = data.get('page_token')
            else:
                print(f"âŒ æŸ¥è¯¢å¤±è´¥: {result.get('msg')}")
                break
                
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¼‚å¸¸: {e}")
            break
    
    print(f"âœ“ æ‰¾åˆ° {len(all_records)} æ¡ç°æœ‰è®°å½•")
    return all_records

def build_record_key(record):
    """æ„å»ºè®°å½•çš„å”¯ä¸€é”®ï¼ˆæ—¥æœŸ + å•å…ƒIDï¼‰"""
    fields = record.get('fields', {})
    
    # å¤„ç†å­—æ®µå€¼ï¼ˆå¯èƒ½æ˜¯å­—å…¸æˆ–å­—ç¬¦ä¸²ï¼‰
    date_field = fields.get('æ—¶é—´', '')
    unit_id_field = fields.get('å•å…ƒID', '')
    
    # æå–å®é™…å€¼
    if isinstance(date_field, dict):
        date = date_field.get('text', '')
    else:
        date = str(date_field)
    
    if isinstance(unit_id_field, dict):
        unit_id = unit_id_field.get('text', '')
    else:
        unit_id = str(unit_id_field)
    
    return f"{date}_{unit_id}"

def filter_duplicates(new_data, existing_records):
    """è¿‡æ»¤é‡å¤æ•°æ®"""
    print(f"\nğŸ” æ£€æŸ¥é‡å¤æ•°æ®...")
    
    # æ„å»ºå·²å­˜åœ¨è®°å½•çš„é”®é›†åˆ
    existing_keys = set()
    for record in existing_records:
        key = build_record_key(record)
        if key:
            existing_keys.add(key)
    
    print(f"   å·²å­˜åœ¨çš„è®°å½•é”®: {len(existing_keys)} ä¸ª")
    
    # è¿‡æ»¤æ–°æ•°æ®
    unique_data = []
    duplicate_count = 0
    
    for item in new_data:
        date = item.get('stat_time_day', '')
        unit_id = str(item.get('promotion_id', ''))
        key = f"{date}_{unit_id}"
        
        if key not in existing_keys:
            unique_data.append(item)
        else:
            duplicate_count += 1
    
    print(f"   æ–°æ•°æ®: {len(new_data)} æ¡")
    print(f"   é‡å¤: {duplicate_count} æ¡")
    print(f"   éœ€è¦å†™å…¥: {len(unique_data)} æ¡")
    
    return unique_data

def delete_records_by_date(token, date_str):
    """åˆ é™¤æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰è®°å½•"""
    print(f"\nğŸ—‘ï¸  åˆ é™¤ {date_str} çš„æ—§è®°å½•...")
    
    # å…ˆæŸ¥è¯¢è¯¥æ—¥æœŸçš„è®°å½•
    records = get_existing_records(token, date_str)
    
    if not records:
        print("   æ²¡æœ‰éœ€è¦åˆ é™¤çš„è®°å½•")
        return True
    
    # æ‰¹é‡åˆ é™¤
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{FEISHU_APP_TOKEN}/tables/{FEISHU_TABLE_ID}/records/batch_delete"
    
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }
    
    # æå–è®°å½•ID
    record_ids = [r.get('record_id') for r in records if r.get('record_id')]
    
    # åˆ†æ‰¹åˆ é™¤ï¼ˆæ¯æ‰¹æœ€å¤š500æ¡ï¼‰
    batch_size = 500
    deleted_count = 0
    
    for i in range(0, len(record_ids), batch_size):
        batch = record_ids[i:i+batch_size]
        payload = {"records": batch}
        
        try:
            resp = requests.post(url, headers=headers, json=payload, timeout=30)
            result = resp.json()
            
            if result.get('code') == 0:
                deleted_count += len(batch)
                print(f"   âœ“ åˆ é™¤ç¬¬ {i//batch_size + 1} æ‰¹: {len(batch)} æ¡")
            else:
                print(f"   âŒ åˆ é™¤å¤±è´¥: {result.get('msg')}")
        except Exception as e:
            print(f"   âŒ åˆ é™¤å¼‚å¸¸: {e}")
    
    print(f"   âœ… å…±åˆ é™¤ {deleted_count} æ¡è®°å½•")
    return deleted_count > 0

def check_duplicates_for_date(date_str):
    """æ£€æŸ¥æŒ‡å®šæ—¥æœŸæ˜¯å¦æœ‰é‡å¤æ•°æ®"""
    print("="*60)
    print(f"æ£€æŸ¥ {date_str} çš„é‡å¤æ•°æ®")
    print("="*60 + "\n")
    
    token = get_feishu_token()
    if not token:
        print("âŒ æ— æ³•è·å–é£ä¹¦ token")
        return
    
    records = get_existing_records(token, date_str)
    
    if not records:
        print(f"\nâœ… {date_str} æ²¡æœ‰æ•°æ®")
        return
    
    # ç»Ÿè®¡é‡å¤
    key_count = {}
    for record in records:
        key = build_record_key(record)
        if key:
            key_count[key] = key_count.get(key, 0) + 1
    
    # æ‰¾å‡ºé‡å¤çš„
    duplicates = {k: v for k, v in key_count.items() if v > 1}
    
    if duplicates:
        print(f"\nâš ï¸  å‘ç°é‡å¤æ•°æ®:")
        for key, count in duplicates.items():
            print(f"   {key}: {count} æ¡")
        
        print(f"\nğŸ’¡ å»ºè®®è¿è¡Œå»é‡:")
        print(f"   python3 dedup.py clean {date_str}")
    else:
        print(f"\nâœ… {date_str} æ²¡æœ‰é‡å¤æ•°æ®")
    
    print("\n" + "="*60)

if __name__ == '__main__':
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•:")
        print("  python3 dedup.py check <æ—¥æœŸ>     # æ£€æŸ¥æŒ‡å®šæ—¥æœŸçš„é‡å¤")
        print("  python3 dedup.py clean <æ—¥æœŸ>     # åˆ é™¤æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰è®°å½•")
        print("\nç¤ºä¾‹:")
        print("  python3 dedup.py check 2026-02-11")
        print("  python3 dedup.py clean 2026-02-11")
        sys.exit(1)
    
    command = sys.argv[1]
    
    if command == "check":
        if len(sys.argv) < 3:
            # é»˜è®¤æ£€æŸ¥æ˜¨å¤©
            from datetime import timedelta
            date_str = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        else:
            date_str = sys.argv[2]
        
        check_duplicates_for_date(date_str)
    
    elif command == "clean":
        if len(sys.argv) < 3:
            print("âŒ è¯·æŒ‡å®šæ—¥æœŸ")
            sys.exit(1)
        
        date_str = sys.argv[2]
        
        print("="*60)
        print(f"æ¸…ç† {date_str} çš„æ•°æ®")
        print("="*60 + "\n")
        
        confirm = input(f"âš ï¸  ç¡®è®¤åˆ é™¤ {date_str} çš„æ‰€æœ‰è®°å½•ï¼Ÿ(yes/no): ")
        
        if confirm.lower() == 'yes':
            token = get_feishu_token()
            if token:
                delete_records_by_date(token, date_str)
        else:
            print("å·²å–æ¶ˆ")
